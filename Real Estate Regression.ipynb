{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256ff175-fae7-4e8d-b657-771577bb2410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!DOCTYPE html><html lang=\"az\"><head><title>Mənzil almaq, Bakı - bina.az</title><meta charset=\"UTF-8\" /><meta content=\"Azərbaycanda pulsuz daşınmaz əmlak elanları - bina.az. Mənzil almaq, Bakı kateqoriyasında bütün elanlar\" name=\"description\" /><link href=\"https://bina.azstatic.com/assets/favicons/favicon-192x192-b40ea6169e17d157d4e6943453ee0f32374348b53abc40010d2ff8c81a2263ec.png\" rel=\"apple-touch-icon\" sizes=\"192x192\" /><link href=\"https://bina.azstatic.com/assets/favicons/favicon-192x192-b40e\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://bina.az/baki/alqi-satqi/menziller'\n",
    "api_key = 'a418ec7a1656038d81e4409b0e575eff'  # Replace with your ScraperAPI key  \n",
    "proxy_url = f'http://api.scraperapi.com?api_key={api_key}&url={url}'\n",
    "\n",
    "response = requests.get(proxy_url)\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.text[:500]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "60932697-b7c4-41e6-83f7-c8207108ccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etracted 28 total listings from https://bina.az/baki/kiraye/menziller\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_listings(first_page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9893ae34-066a-4515-b66b-77b1920d2581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller . total listenings 28\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=151 . total listenings 56\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=152 . total listenings 84\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=153 . total listenings 111\n",
      "Etracted 27  listings from https://bina.az/baki/alqi-satqi/menziller?page=154 . total listenings 138\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=155 . total listenings 165\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=156 . total listenings 192\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=157 . total listenings 220\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=158 . total listenings 248\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=159 . total listenings 275\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=160 . total listenings 302\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=161 . total listenings 330\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=162 . total listenings 356\n",
      "Etracted 27  listings from https://bina.az/baki/alqi-satqi/menziller?page=163 . total listenings 383\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=164 . total listenings 410\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=165 . total listenings 436\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=166 . total listenings 464\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=167 . total listenings 492\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=168 . total listenings 519\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=169 . total listenings 547\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=170 . total listenings 574\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=171 . total listenings 600\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=172 . total listenings 627\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=173 . total listenings 655\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=174 . total listenings 683\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=175 . total listenings 710\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=176 . total listenings 738\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=177 . total listenings 764\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=178 . total listenings 790\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=179 . total listenings 818\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=180 . total listenings 844\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=181 . total listenings 870\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=182 . total listenings 897\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=183 . total listenings 924\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=184 . total listenings 950\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=185 . total listenings 976\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=186 . total listenings 1003\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=187 . total listenings 1030\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=188 . total listenings 1058\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=189 . total listenings 1086\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=190 . total listenings 1113\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=191 . total listenings 1138\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=192 . total listenings 1164\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=193 . total listenings 1192\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=194 . total listenings 1219\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=195 . total listenings 1244\n",
      "Etracted 0  listings from https://bina.az/baki/alqi-satqi/menziller?page=196 . total listenings 1244\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=197 . total listenings 1271\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=198 . total listenings 1299\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=199 . total listenings 1327\n",
      "Etracted 28  listings from https://bina.az/baki/alqi-satqi/menziller?page=200 . total listenings 1355\n",
      "\n",
      "✅ Scraping finished! Total unique listings extracted: 1355\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "html_content=response.text\n",
    "soup=BeautifulSoup(html_content,\"html.parser\")\n",
    "\n",
    "href=soup.find_all('a' ,href=True)\n",
    "href\n",
    "\n",
    "\n",
    "first_page_url='https://bina.az/baki/alqi-satqi/menziller'\n",
    "base_url='https://bina.az/baki/alqi-satqi/menziller?page='\n",
    "\n",
    "current_page=2\n",
    "max_page=200\n",
    "linkdata=set()\n",
    "\n",
    "\n",
    "def scrape_listings(url):\n",
    "    \n",
    "    api_key = 'a418ec7a1656038d81e4409b0e575eff'  # Replace with your ScraperAPI key\n",
    "    proxy_url = f'http://api.scraperapi.com?api_key={api_key}&url={url}'\n",
    "\n",
    "    response = requests.get(proxy_url)\n",
    "\n",
    "# checking url status \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed fetch url {url} ,stopping\")\n",
    "        return False\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    soup=BeautifulSoup(response.text,\"html.parser\")\n",
    "\n",
    "    href=soup.find_all('a' ,href=True)\n",
    "\n",
    "\n",
    "    new_linkset=set()\n",
    "    for link in href:\n",
    "        linkset=link['href']\n",
    "        if '/items/' in linkset and all(x not in linkset for x in ['=','all','new']):\n",
    "            new_linkset.add('https://bina.az'+linkset)\n",
    "\n",
    "    linkdata.update(new_linkset)\n",
    "            \n",
    "    print(f\"Etracted {len(new_linkset)}  listings from {url} . total listenings {len(linkdata)}\")\n",
    "    return True\n",
    "\n",
    "scrape_listings(first_page_url)\n",
    "\n",
    "while current_page<=max_page:\n",
    "    page_url=f\"{base_url}{current_page}\"\n",
    "    success=scrape_listings(page_url)\n",
    "\n",
    "\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    current_page +=1\n",
    "\n",
    "\n",
    "print(f\"\\n✅ Scraping finished! Total unique listings extracted: {len(linkdata)}\")\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fbae041-b8b4-444c-af1c-f91996c3eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Dublicate\n"
     ]
    }
   ],
   "source": [
    "seen=set()\n",
    "dublicates=set()\n",
    "\n",
    "for links in linkdata2:\n",
    "    if links in seen:\n",
    "        dublicates.add(links)\n",
    "    else :\n",
    "        seen.add(links)\n",
    "\n",
    "if dublicates:\n",
    "    print('Dublicate link found' ,dublicates)\n",
    "else :\n",
    "    print('No Dublicate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a94be3-19d1-47ee-8807-a4078ed368ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac4cba9-82d8-4a69-886c-a3d59811ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datafram from linkdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeee3eab-4579-4a7b-b29e-81e15c445833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted link count : https://bina.az/items/5004576\n",
      "Extracted link count : https://bina.az/items/4936652\n",
      "Extracted link count : https://bina.az/items/5015922\n",
      "Extracted link count : https://bina.az/items/4894081\n",
      "Extracted link count : https://bina.az/items/4808605\n",
      "Extracted link count : https://bina.az/items/5074158\n",
      "Extracted link count : https://bina.az/items/5091922\n",
      "Extracted link count : https://bina.az/items/4621986\n",
      "Extracted link count : https://bina.az/items/5074794\n",
      "Extracted link count : https://bina.az/items/4404201\n",
      "Extracted link count : https://bina.az/items/5068771\n",
      "Extracted link count : https://bina.az/items/4952660\n",
      "Extracted link count : https://bina.az/items/5077973\n",
      "Extracted link count : https://bina.az/items/5107895\n",
      "Extracted link count : https://bina.az/items/5049499\n",
      "Extracted link count : https://bina.az/items/5095426\n",
      "Extracted link count : https://bina.az/items/5066913\n",
      "Extracted link count : https://bina.az/items/5072364\n",
      "Extracted link count : https://bina.az/items/5096274\n",
      "Extracted link count : https://bina.az/items/5024480\n",
      "Extracted link count : https://bina.az/items/4904799\n",
      "Extracted link count : https://bina.az/items/5013410\n",
      "Extracted link count : https://bina.az/items/5105439\n",
      "Extracted link count : https://bina.az/items/5106904\n",
      "        Category  Area_m2 Floor Building_Floor_count Room_Count   Price  \\\n",
      "0   Köhnə tikili    45 m²    4                     5          2   96000   \n",
      "1    Yeni tikili   140 m²   11                    18          3  360000   \n",
      "2    Yeni tikili  74.5 m²    4                    20          2  149000   \n",
      "3    Yeni tikili   116 m²    6                    16          3  255000   \n",
      "4    Yeni tikili   200 m²    5                    18          4  445000   \n",
      "5    Yeni tikili   140 m²    6                    10          3  672000   \n",
      "6   Köhnə tikili    42 m²    5                     5          2   97000   \n",
      "7   Köhnə tikili    80 m²    8                     9          3  205000   \n",
      "8   Köhnə tikili    40 m²    5                     5          2  149000   \n",
      "9    Yeni tikili  81.6 m²    1                    20          2  187680   \n",
      "10  Köhnə tikili    35 m²    3                     5          1   99000   \n",
      "11   Yeni tikili    95 m²    2                    17          3  175000   \n",
      "12   Yeni tikili   105 m²    3                    17          3  190000   \n",
      "13   Yeni tikili   143 m²    4                     8          4  264000   \n",
      "14  Köhnə tikili   115 m²    7                     9          4  259000   \n",
      "15   Yeni tikili   135 m²    4                    16          3  425000   \n",
      "16   Yeni tikili  47.5 m²    2                     7          1  186000   \n",
      "17   Yeni tikili    60 m²   13                    17          2  172000   \n",
      "18   Yeni tikili   102 m²    9                    18          2  268000   \n",
      "19   Yeni tikili   127 m²   16                    20          3  373000   \n",
      "20   Yeni tikili   100 m²    6                    18          3  309000   \n",
      "21   Yeni tikili   110 m²   12                    18          3  309000   \n",
      "22   Yeni tikili   155 m²    4                    20          4  285000   \n",
      "23  Köhnə tikili    45 m²    8                     9          2  155000   \n",
      "\n",
      "   Currency                                           Location  Repair  \\\n",
      "0       AZN                 [' Neftçilər m.', '', 'Nizami r.']     var   \n",
      "1       AZN  [' Zabitlər parkı', '', ' Sirk', '', ' Azərbay...     var   \n",
      "2       AZN  [' İnşaatçılar m.', '', 'Yasamal r.', '', 'Yen...  yoxdur   \n",
      "3       AZN                     [' Səbail r.', '', 'Bayıl q.']     var   \n",
      "4       AZN  [' Azərbaycan Dövlət Neft və Sənaye Universite...     var   \n",
      "5       AZN  [' Ağ şəhər', '', ' Xətai r.', '', 'Ağ şəhər q.']  yoxdur   \n",
      "6       AZN          [' Xalqlar Dostluğu m.', '', 'Nizami r.']     var   \n",
      "7       AZN                    [' Xətai r.', '', 'Əhmədli m.']     var   \n",
      "8       AZN  [' Elmlər Akademiyası m.', '', 'Hüseyn Cavid p...     var   \n",
      "9       AZN                [' 20 Yanvar m.', '', 'Yasamal r.']     var   \n",
      "10      AZN  [' Qara Qarayev m.', '', 'Nizami r.', '', '8-c...     var   \n",
      "11      AZN  [' İnşaatçılar m.', '', 'Yasamal r.', '', 'Yen...  yoxdur   \n",
      "12      AZN              [' Xətai r.', '', 'Köhnə Günəşli q.']     var   \n",
      "13      AZN                [' Sabunçu r.', '', 'Bakıxanov q.']  yoxdur   \n",
      "14      AZN  [' ASAN Xidmət №1', '', ' Tibb Universiteti', ...     var   \n",
      "15      AZN          [' Şah İsmayıl Xətai m.', '', 'Xətai r.']  yoxdur   \n",
      "16      AZN  [' Sabunçu r.', '', 'Nardaran q.', '', 'Sea Br...  yoxdur   \n",
      "17      AZN  [' Qara Qarayev m.', '', 'Koroğlu m.', '', 'Ni...     var   \n",
      "18      AZN      [' Nəriman Nərimanov m.', '', 'Nərimanov r.']     var   \n",
      "19      AZN  [' Şah İsmayıl Xətai m.', '', 'Xətai r.', '', ...  yoxdur   \n",
      "20      AZN  [' ASAN Xidmət №1', '', ' Tibb Universiteti', ...     var   \n",
      "21      AZN                  [' Səbail r.', '', 'Badamdar q.']     var   \n",
      "22      AZN               [' Həzi Aslanov m.', '', 'Xətai r.']     var   \n",
      "23      AZN      [' Nəriman Nərimanov m.', '', 'Nərimanov r.']     var   \n",
      "\n",
      "   Distirict  \n",
      "0    Nəsimi   \n",
      "1    Nəsimi   \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5        NaN  \n",
      "6     Xətai   \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9    Bakı ş.  \n",
      "10       NaN  \n",
      "11       NaN  \n",
      "12    Xətai   \n",
      "13       NaN  \n",
      "14  Yasamal   \n",
      "15    Xətai   \n",
      "16       NaN  \n",
      "17       NaN  \n",
      "18    Xətai   \n",
      "19       NaN  \n",
      "20       NaN  \n",
      "21       NaN  \n",
      "22       NaN  \n",
      "23    Xətai   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "Proporties_info=pd.DataFrame(columns=['Category','Area_m2','Floor','Building_Floor_count','Room_Count','Price','Currency','Location','Repair','Distirict'])\n",
    "rows = []\n",
    "\n",
    "\n",
    "for itm in linkdata:\n",
    "    try: \n",
    "\n",
    "        api_key = 'a418ec7a1656038d81e4409b0e575eff'  # Replace with your ScraperAPI key\n",
    "        proxy_url = f'http://api.scraperapi.com?api_key={api_key}&url={itm}'\n",
    "\n",
    "        response = requests.get(proxy_url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch {itm}\")\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        \n",
    "        kiraye=soup.find_all('div' , class_= 'product-properties__column')\n",
    "        price=soup.find_all('div',class_='product-price')\n",
    "        location=soup.find_all('ul' , class_='product-extras bz-d-flex bz-align-center bz-gap-15 bz-wrap-wrap')\n",
    "        lct=soup.find_all('a' ,class_='open_map')\n",
    "        ozellikler= re.sub('<[^>]+>', ' ', str(kiraye)).split('  ')  # neticeye bax orda '' isaresi niye silmek olmur\n",
    "        loc=re.sub('<[^>]+>',' ',str(location)).split('  ') \n",
    "        lc=re.sub('<[^>]+>' , ' ', str(lct)).split('  ')\n",
    "        price=re.sub('<[^>]+>', ' ' ,str(price)).split ('  ')\n",
    "\n",
    "\n",
    "        if len(ozellikler)>14 and len(price)>3:\n",
    "            kategoriya=ozellikler[2]\n",
    "            sahe=ozellikler[8].replace('m2','')\n",
    "            mertebe=ozellikler[5]\n",
    "            otag_sayi=ozellikler[11]\n",
    "            qiymet=price[1].replace(' ','')\n",
    "            kira_novu=price[3].replace('/','')\n",
    "            valyuta=price[2]\n",
    "            erazi=str(loc[1:-1]).replace('m2','')\n",
    "            temir=ozellikler[14]\n",
    "            Rayon=lc[0].split(', ')\n",
    "            District=Rayon[1].replace('r.','') if len(Rayon) > 1 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "            new_row = {\n",
    "                'Category': kategoriya,\n",
    "                'Area_m2': sahe,\n",
    "                'Floor': mertebe.split('/')[0],\n",
    "                'Building_Floor_count' : mertebe.split('/')[1],\n",
    "                'Room_Count': otag_sayi,\n",
    "                'Price': qiymet,\n",
    "                'Currency': valyuta,\n",
    "                'Location': erazi,\n",
    "                'Repair': temir,\n",
    "                'Distirict' : District\n",
    "            } \n",
    "\n",
    "\n",
    "            rows.append(new_row)\n",
    "            print(f\"Extracted link count : {itm}\")\n",
    "            \n",
    "            # Add the new row to the list\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "if rows:\n",
    "    df = pd.concat([Proporties_info, pd.DataFrame(rows)], ignore_index=True)\n",
    "    print(Proporties_Data)\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b270fb-4422-41b1-85db-b621cc36f1bb",
   "metadata": {},
   "source": [
    "#Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b57baef8-6c2d-49b7-b988-67f4d81db9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataframe shape : {df.shape} ')\n",
    "\n",
    "print('Null values count by columns')\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(' Datframe columns descriptions')\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df80988-56b4-4eb2-a434-20927ccec712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def avg_price (row):\n",
    "\n",
    "    if row['Price']<=100000:\n",
    "        return 100000\n",
    "    elif row['Price'] >100000 and row['Price'] <=200000:\n",
    "        return 200000\n",
    "    elif row['Price']>200000 and row['Price']<=300000:\n",
    "        return 300000\n",
    "    elif row['Price']>300000 and row['Price']<=500000:\n",
    "        return 500000\n",
    "    elif row['Price']>500000 and row ['Price']<=700000:\n",
    "        return 700000\n",
    "    elif row['Price']>700000 and row ['Price']<=1000000:\n",
    "        return 1000000\n",
    "    else:\n",
    "        return +1000000\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25513b29-eaa3-4297-9102-fff7a234bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avg_Price'] = df.apply(avg_price, axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b485d8f-84c5-41df-a99a-03ad52505f56",
   "metadata": {},
   "source": [
    "Distirubition of numeric columuns accros to the Price values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da38a0f-b902-4381-8720-de698651be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "column_list=['Category','Floor','Room_Count','Repair','Price']\n",
    "\n",
    "def histogram_columns(data):\n",
    "\n",
    "    filtered_columns=[col for col in column_list if col !='Price']\n",
    "\n",
    "    for clmn in filtered_columns:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.kdeplot(data=data,x='Price' ,hue=clmn ,shade=True)\n",
    "        \n",
    "        plt.title(f'Distribution of {clmn} according to Price')\n",
    "        plt.xlabel(clmn)\n",
    "        plt.ylabel('Density')\n",
    "        plt.show()\n",
    "histogram_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8c22d-42d9-40ee-8269-0d9160f8b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore all columns by histogram\n",
    "def histogram_of_columns(data):\n",
    "    \n",
    "    for clmn in data.columns:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.histplot(data[clmn] ,kde=False)\n",
    "        plt.title(clmn)\n",
    "        plt.xlabel(clmn)\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "histogram_of_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8a84a-7bca-4697-9cc6-8c9786d0c704",
   "metadata": {},
   "source": [
    "Cleaning miss values  and Modifying columuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825a84a-360a-4938-8470-d95665c1ef0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd0f2c8-1cb5-4138-85fb-72e4b2ae4e1d",
   "metadata": {},
   "source": [
    "#Cleaning miss values and modifying columuns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450dfe2-7291-46ef-8c0e-6dff2faff9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f16eae-5fe5-4573-9c2a-819a5cf78125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove m2 in Area_m2 column\n",
    "\n",
    "df['Area_m2']=df['Area_m2'].str.replace(r'\\D+' , '',regex=True).astype(int)\n",
    "\n",
    "\n",
    "# Fill the null values in Distirict columns  with values which contains in Location \n",
    "\n",
    "def location_clmn(row):\n",
    "    # Only process rows where Distirict is NaN\n",
    "    if pd.fisna(row['Distirict']):\n",
    "        # Split Location by comma (handle multiple parts)\n",
    "        location_parts = row['Location'].split(',')\n",
    "        \n",
    "        # Iterate through each part of Location\n",
    "        for loc in location_parts:\n",
    "            if ' r.' in loc:  # Check if 'r' is in the location part\n",
    "                # Return modified location (remove 'r' and strip spaces)\n",
    "                cleaned = loc.replace(' r.', '').replace(' r.]', '').replace(']' , '').replace('[' , '' ).replace(' r', '').replace(\"'\" , '').strip()\n",
    "\n",
    "                \n",
    "\n",
    "                return cleaned\n",
    "        \n",
    "        # If no part of Location contains 'r', return 'Unknown'\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # If Distirict is not NaN, return the original value\n",
    "    return row['Distirict']\n",
    "\n",
    "df['New District']=df.apply(location_clmn,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f134c-8f8c-442f-90c1-50cc675fa813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create top 5 District \n",
    "df.columns\n",
    "df['New District']=df['New District'].str.replace(' ' , '').str.strip()\n",
    "#df['New District'].unique()\n",
    "top_5_distirict=df['New District'].value_counts().head(5).index.tolist()\n",
    "df['District_5']=df['New District'].apply(lambda x : x if x in top_5_distirict else 'Other' )\n",
    "df['District_5'].unique()\n",
    "# Remove some useless columns\n",
    "df.drop(columns=['Currency','Location','Distirict','New District'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d7c18-c6c7-421d-8d7c-0b64cfd9c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(10))\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc11d7-6aeb-4327-90e9-dcd4f58ced18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bc80a-090e-4ea9-9f42-f8769f38677c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784280f-ffce-4318-b241-be0952a83408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d3c8e-0675-42ae-b61f-8017a7bf7519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663be14-5377-4cf4-ad74-cde6561e2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect columns which are has outliers \n",
    "\n",
    "columun_list=['Area_m2','Floor','Building_Floor_count','Room_Count','Price']\n",
    "\n",
    "for i in df_dummies[columun_list] :\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.boxplot(x=df_dummies[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae92af6-9714-4850-a1a2-b346d0e5c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Outliers on price columun\n",
    "# Considering leaner regression model therefore would better  in order to  remove outliers in target \n",
    "# remove Target outliers (Price)\n",
    "\n",
    "print(f'Before remove outliers : {df_dummies.shape}')\n",
    "Q1=df_dummies['Price'].quantile(0.25)\n",
    "Q3=df_dummies['Price'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "df_without_out=df_dummies[df_dummies['Price']<=(Q3+1.5*IQR)]\n",
    "price_outliers\n",
    "\n",
    "print(f'After remove outliers : {df_without_out.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ce0ca-d526-4320-a3fe-31e8bd339d68",
   "metadata": {},
   "source": [
    "One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d473892-e270-4366-9270-4246ab214068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform some columuns as Dummy (One-hot encoding)\n",
    "df_dummies=pd.get_dummies(df,columns=['Category','Repair','District_5'],drop_first=True,dtype='int')\n",
    "df_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340ef77-f743-4e29-a45e-badcdbb9936f",
   "metadata": {},
   "source": [
    "Corrolation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb495f2-6239-45c7-977c-18e002e64d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corralation test\n",
    "\n",
    "correlation_matrix=df_dummies.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(correlation_matrix , annot=True , cmap='coolwarm' )\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8a18d-5745-4dfb-b221-df958e2fa3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheking regression between target and independent columns \n",
    "\n",
    "cols=[ 'Area_m2','Floor' ,'Building_Floor_count' ,'Room_Count']\n",
    "plt.figure(figsize=(20,30))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    plt.subplot(5, 3, i + 1)\n",
    "    plt.title(cols[i] + ' - Price')\n",
    "    \n",
    "    \n",
    "    sns.regplot(x=df_dummies[cols[i]], y=df_dummies.Price)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0649cb2d-1245-4f4c-a085-47055346e561",
   "metadata": {},
   "source": [
    "Split Train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b029a-c168-4959-8d2c-958802eaf330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(columns=['Price','Avg_Price'])\n",
    "y=df['Price']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "print(f'X_train :{X_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_train :{y_train.shape}')\n",
    "print(f'y_test :{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df652db-f727-44f4-b6d2-b5d55c49a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate 3 type of model in order to decide best one \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Loop through each model and evaluate\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"🔹 {name}\")\n",
    "    print(f\"   ✅ MSE: {mse:.2f}\")\n",
    "    print(f\"   ✅ R² Score: {r2:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93fc815-9ab9-4f2a-a7bf-5e5942e28a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2173b08-b48f-4c98-bada-663a0653ddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbfc98-1471-4249-b27e-b34e0e288c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b7930-9cfa-4abb-83ad-76942f7a0649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179188e-23d6-4668-88c3-b62a1518424a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac3a60-0ed3-4502-a63e-58a702752187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ef199a-fed6-4e7b-bf61-cedc6bba9549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af2c53-1c4a-46fe-9f4b-4dd101e9b654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
